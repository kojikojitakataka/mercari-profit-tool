import streamlit as st
import urllib.parse
import pandas as pd
from datetime import datetime
from PIL import Image
import torch
import clip
import matplotlib.pyplot as plt
import base64

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ãƒªã‚µãƒ¼ãƒãƒŠãƒ“", layout="wide")
st.title("ğŸ” ãƒªã‚µãƒ¼ãƒãƒŠãƒ“ï¼ˆResearchNaviï¼‰")
st.caption("ğŸ“¦ ç”»åƒâ†’å•†å“åæ¨å®š â†’ ECæ¤œç´¢ â†’ åˆ©ç›Šè¨ˆç®—ï¼†å±¥æ­´ã‚°ãƒ©ãƒ• + é›»è„³ã›ã©ã‚Šæ”¯æ´")

# ãƒšãƒ¼ã‚¸åˆ‡ã‚Šæ›¿ãˆ
page = st.sidebar.radio("ğŸ§­ ãƒšãƒ¼ã‚¸åˆ‡æ›¿", ["ç”»åƒæ¤œç´¢", "åˆ©ç›Šè¨ˆç®—ï¼†å±¥æ­´", "é›»è„³ã›ã©ã‚Š"])

# =================== 1. ç”»åƒæ¤œç´¢ ===================
if page == "ç”»åƒæ¤œç´¢":
    st.subheader("ğŸ–¼ï¸ å•†å“ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨AIæ¨å®š")
    uploaded_image = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆjpg, pngï¼‰", type=["jpg", "jpeg", "png"])
    item_name = ""

    if uploaded_image:
        st.image(uploaded_image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", use_container_width=True)
        st.info("ğŸ” AIãŒå•†å“åã‚’æ¨å®šä¸­...")

        image = Image.open(uploaded_image).convert("RGB")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model, preprocess = clip.load("ViT-B/32", device=device)
        image_input = preprocess(image).unsqueeze(0).to(device)

        # ä»®ã®å€™è£œï¼ˆæ—¥æœ¬èªCLIPæœªçµ±åˆã®ãŸã‚ç°¡æ˜“ï¼‰
        candidate_names = [
            "AirPods Pro", "iPhone", "PlayStation 5", "Nintendo Switch", "ç‚Šé£¯å™¨", "ç¾å®¹å®¶é›»", "ãƒªãƒ¥ãƒƒã‚¯", "ã‚¹ãƒ‹ãƒ¼ã‚«ãƒ¼"
        ]
        text_tokens = clip.tokenize(candidate_names).to(device)
        with torch.no_grad():
            image_features = model.encode_image(image_input)
            text_features = model.encode_text(text_tokens)
            similarity = (image_features @ text_features.T).softmax(dim=-1)
        best_idx = similarity[0].argmax().item()
        item_name = candidate_names[best_idx]
        st.success(f"âœ… æ¨å®šå•†å“å: **{item_name}**")

    item_name = st.text_input("ğŸ“ å•†å“åã‚’ç¢ºèªãƒ»ä¿®æ­£", value=item_name or "")
    if item_name:
        st.subheader("ğŸ”— ECã‚µã‚¤ãƒˆæ¤œç´¢ãƒªãƒ³ã‚¯")
        keyword = urllib.parse.quote(item_name)
        ec_links = {
            "Amazon": f"https://www.amazon.co.jp/s?k={keyword}",
            "æ¥½å¤©å¸‚å ´": f"https://search.rakuten.co.jp/search/mall/{keyword}/",
            "Yahooã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°": f"https://shopping.yahoo.co.jp/search?p={keyword}",
            "ãƒ¡ãƒ«ã‚«ãƒªï¼ˆå£²ã‚Šåˆ‡ã‚Œï¼‰": f"https://www.mercari.com/jp/search/?keyword={keyword}&status=sold_out",
            "PayPayãƒ•ãƒªãƒ": f"https://paypayfleamarket.yahoo.co.jp/search?query={keyword}",
            "1688.com": f"https://s.1688.com/selloffer/offer_search.htm?keywords={keyword}",
            "Costco": f"https://www.costco.co.jp/CatalogSearch?keyword={keyword}",
            "ãƒ‰ãƒ³ãƒ»ã‚­ãƒ›ãƒ¼ãƒ†": f"https://www.google.com/search?q={keyword}+site:donki.com"
        }
        for name, url in ec_links.items():
            st.markdown(f"- [{name}]({url}) ğŸ”—", unsafe_allow_html=True)

# =================== 2. åˆ©ç›Šè¨ˆç®—ï¼†å±¥æ­´ ===================
elif page == "åˆ©ç›Šè¨ˆç®—ï¼†å±¥æ­´":
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ’° åˆ©ç›Šè¨ˆç®—")
        price = st.number_input("è²©å£²ä¾¡æ ¼ï¼ˆå††ï¼‰", value=1000)
        shipping = st.number_input("é€æ–™ï¼ˆå††ï¼‰", value=200)
        cost = st.number_input("ä»•å…¥ã‚Œå€¤ï¼ˆå††ï¼‰", value=500)

        fee = price * 0.1
        profit = price - fee - shipping - cost

        st.metric("ğŸ§¾ æ‰‹æ•°æ–™", f"{fee:.0f} å††")
        st.metric("ğŸ“ˆ åˆ©ç›Š", f"{profit:.0f} å††")

        if st.button("ğŸ’¾ åˆ©ç›Šãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"):
            now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            df = pd.DataFrame([{
                "æ—¥æ™‚": now,
                "è²©å£²ä¾¡æ ¼": price,
                "é€æ–™": shipping,
                "ä»•å…¥ã‚Œå€¤": cost,
                "æ‰‹æ•°æ–™": fee,
                "åˆ©ç›Š": profit
            }])
            try:
                existing = pd.read_csv("profit_history.csv")
                df.to_csv("profit_history.csv", mode="a", index=False, header=False)
            except:
                df.to_csv("profit_history.csv", index=False)
            st.success("âœ… ä¿å­˜ã—ã¾ã—ãŸï¼")

    with col2:
        st.subheader("ğŸ“Š åˆ©ç›Šå±¥æ­´ã‚°ãƒ©ãƒ•")
        try:
            data = pd.read_csv("profit_history.csv")
            st.dataframe(data.tail(10))

            st.markdown("#### åˆ©ç›Šã®æ¨ç§»ï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰")
            fig1, ax1 = plt.subplots()
            data["æ—¥æ™‚"] = pd.to_datetime(data["æ—¥æ™‚"])
            ax1.bar(data["æ—¥æ™‚"], data["åˆ©ç›Š"])
            ax1.set_ylabel("åˆ©ç›Š (å††)")
            ax1.tick_params(axis='x', rotation=45)
            st.pyplot(fig1)

            st.markdown("#### ã‚³ã‚¹ãƒˆå†…è¨³ï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰")
            last = data.iloc[-1]
            labels = ['è²©å£²ä¾¡æ ¼', 'æ‰‹æ•°æ–™', 'é€æ–™', 'ä»•å…¥ã‚Œå€¤', 'åˆ©ç›Š']
            sizes = [last['è²©å£²ä¾¡æ ¼'], last['æ‰‹æ•°æ–™'], last['é€æ–™'], last['ä»•å…¥ã‚Œå€¤'], last['åˆ©ç›Š']]
            fig2, ax2 = plt.subplots()
            ax2.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
            st.pyplot(fig2)

        except:
            st.warning("ğŸ“­ ã¾ã å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# =================== 3. é›»è„³ã›ã©ã‚Š ===================
elif page == "é›»è„³ã›ã©ã‚Š":
    st.subheader("ğŸ›ï¸ é›»è„³ã›ã©ã‚Šã‚·ãƒ§ãƒƒãƒ—æ¤œç´¢")
    keyword = st.text_input("ğŸ” å•†å“åã‚’å…¥åŠ›", "")
    if keyword:
        keyword_encoded = urllib.parse.quote(keyword)
        shops = {
            "ãƒ¨ãƒ‰ãƒã‚·": f"https://www.yodobashi.com/?word={keyword_encoded}",
            "ãƒ“ãƒƒã‚¯ã‚«ãƒ¡ãƒ©": f"https://www.biccamera.com/bc/category/?q={keyword_encoded}",
            "ãƒã‚¸ãƒ": f"https://online.nojima.co.jp/search/?keyword={keyword_encoded}",
            "ã‚¤ã‚ªãƒ³": f"https://shops.aeonsquare.net/search?keyword={keyword_encoded}",
            "Joshin": f"https://joshinweb.jp/search/?KEYWORD={keyword_encoded}"
        }
        for name, url in shops.items():
            st.markdown(f"- [{name}]({url}) ğŸ”—", unsafe_allow_html=True)

    st.markdown("---")
    st.subheader("ğŸ§® é›»å“æ©Ÿèƒ½")
    calc_expr = st.text_input("æ•°å¼ã‚’å…¥åŠ›ï¼ˆä¾‹ï¼š1000-200-100ï¼‰")
    if calc_expr:
        try:
            result = eval(calc_expr)
            st.success(f"âœ… çµæœ: {result}")
        except:
            st.error("âš ï¸ æ•°å¼ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
