import streamlit as st
from PIL import Image
import pandas as pd
import urllib.parse
import datetime
import torch
import clip
import os

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="è¤‡åˆã›ã©ã‚Šå£²è²·ãƒ„ãƒ¼ãƒ«ï¼ˆã‚»ãƒ‰ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ï¼‰", layout="centered")
st.title("ğŸ›ï¸ è¤‡åˆã›ã©ã‚Šå£²è²·ãƒ„ãƒ¼ãƒ«ï¼ˆã‚»ãƒ‰ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ï¼‰")
st.caption("åˆ¶ä½œè€…ï¼šå°å³¶ å´‡å½¦ã€€åˆ¶ä½œæ—¥ï¼š2025å¹´5æœˆ27æ—¥")

# --- ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
uploaded_image = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆjpg, pngï¼‰", type=["jpg", "jpeg", "png"])

# --- å•†å“ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠ ---
genre = st.selectbox(
    "å•†å“ã‚¸ãƒ£ãƒ³ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆä»»æ„ï¼‰",
    [
        "è¡£é¡", "å®¶é›»", "æœ¬ãƒ»é›‘èªŒ", "ãƒ›ãƒ“ãƒ¼", "ãŠã‚‚ã¡ã‚ƒ", "ã‚²ãƒ¼ãƒ ", "ã‚¹ãƒãƒ¼ãƒ„ç”¨å“",
        "ã‚¢ã‚¦ãƒˆãƒ‰ã‚¢", "ç¾å®¹ãƒ»å¥åº·", "é£Ÿå“ãƒ»é£²æ–™", "å®¶å…·ãƒ»ã‚¤ãƒ³ãƒ†ãƒªã‚¢", "ãƒ™ãƒ“ãƒ¼ãƒ»ã‚­ãƒƒã‚º",
        "ãƒšãƒƒãƒˆç”¨å“", "è»Šãƒ»ãƒã‚¤ã‚¯", "æ¥½å™¨", "ãƒã‚±ãƒƒãƒˆ", "ãã®ä»–"
    ]
)

if uploaded_image is not None:
    try:
        image = Image.open(uploaded_image)
        st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_container_width=True)

        # --- CLIPãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å•†å“åäºˆæ¸¬ ---
        st.markdown("ğŸ” **AIã«ã‚ˆã‚‹äºˆæ¸¬å•†å“å:**")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model, preprocess = clip.load("ViT-B/32", device=device)

        # ç”»åƒã®å‰å‡¦ç†
        image_preprocessed = preprocess(image).unsqueeze(0).to(device)

        # å•†å“åã®å€™è£œãƒªã‚¹ãƒˆ
        candidate_labels = [
            "ç™½ã„Tã‚·ãƒ£ãƒ„", "é»’ã„Tã‚·ãƒ£ãƒ„", "é’ã„ã‚¸ãƒ¼ãƒ³ã‚º", "èµ¤ã„ã‚¹ãƒ‹ãƒ¼ã‚«ãƒ¼", "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³",
            "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³", "è…•æ™‚è¨ˆ", "ãƒãƒƒã‚¯ãƒ‘ãƒƒã‚¯", "ã‚®ã‚¿ãƒ¼", "é›»å­ãƒ¬ãƒ³ã‚¸"
        ]

        # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†
        text_tokens = clip.tokenize(candidate_labels).to(device)

        # ç‰¹å¾´é‡ã®å–å¾—
        with torch.no_grad():
            image_features = model.encode_image(image_preprocessed)
            text_features = model.encode_text(text_tokens)

        # é¡ä¼¼åº¦ã®è¨ˆç®—
        image_features /= image_features.norm(dim=-1, keepdim=True)
        text_features /= text_features.norm(dim=-1, keepdim=True)
        similarities = (image_features @ text_features.T).squeeze(0)

        # æœ€ã‚‚é¡ä¼¼åº¦ã®é«˜ã„ãƒ©ãƒ™ãƒ«ã‚’é¸æŠ
        best_match_index = similarities.argmax().item()
        predicted_name = candidate_labels[best_match_index]
        st.success(predicted_name)

        # --- EC/ãƒ•ãƒªãƒ æ¤œç´¢ãƒªãƒ³ã‚¯ ---
        st.subheader("ğŸ”— é–¢é€£ã‚µã‚¤ãƒˆã§æ¤œç´¢")
        encoded_name = urllib.parse.quote(predicted_name)
        col1, col2, col3 = st.columns(3)
        with col1:
            st.link_button("ğŸŸ¥ ãƒ¡ãƒ«ã‚«ãƒª", f"https://www.mercari.com/jp/search/?keyword={encoded_name}")
        with col2:
            st.link_button("ğŸŸ¦ PayPayãƒ•ãƒªãƒ", f"https://paypayfleamarket.yahoo.co.jp/search?query={encoded_name}")
        with col3:
            st.link_button("ğŸŸ¢ æ¥½å¤©å¸‚å ´", f"https://search.rakuten.co.jp/search/mall/{encoded_name}/")
        col4, col5 = st.columns(2)
        with col4:
            st.link_button("ğŸŸ¡ Yahooã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°", f"https://shopping.yahoo.co.jp/search?p={encoded_name}")
        with col5:
            st.link_button("ğŸŸ  Amazon", f"https://www.amazon.co.jp/s?k={encoded_name}")

        # --- ãƒ€ãƒŸãƒ¼ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã§ç›¸å ´è¡¨ç¤º ---
        st.subheader("ğŸ“Š é¡ä¼¼å•†å“ã®ä¾¡æ ¼ç›¸å ´ï¼ˆä¾‹ï¼‰")
        df = pd.DataFrame({
            "å•†å“å": ["Tã‚·ãƒ£ãƒ„", "Tã‚·ãƒ£ãƒ„ ç™½", "ãŠã—ã‚ƒã‚ŒTã‚·ãƒ£ãƒ„"],
            "ä¾¡æ ¼": [1200, 1300, 1250]
        })
        st.bar_chart(df["ä¾¡æ ¼"])
        st.write("ğŸ§® **ä¸­å¤®å€¤ï¼š**", df["ä¾¡æ ¼"].median())
        st.write("ğŸ” **æœ€é »å€¤ï¼š**", df["ä¾¡æ ¼"].mode()[0])
        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button("â¬‡ï¸ é¡ä¼¼å•†å“ã®CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, "similar_products.csv", "text/csv")

        # --- åˆ©ç›Šè¨ˆç®—ãƒ•ã‚©ãƒ¼ãƒ  ---
        st.subheader("ğŸ’° åˆ©ç›Šè¨ˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼")
        col1, col2 = st.columns(2)
        with col1:
            cost_price = st.number_input("ä»•å…¥ã‚Œä¾¡æ ¼ï¼ˆå††ï¼‰", min_value=0)
        with col2:
            sell_price = st.number_input("è²©å£²ä¾¡æ ¼ï¼ˆå††ï¼‰", min_value=0)

        if sell_price > 0:
            fee = int(sell_price * 0.1)  # ãƒ¡ãƒ«ã‚«ãƒª10%æ‰‹æ•°æ–™
            profit = sell_price - fee - cost_price
            st.info(f"ğŸ§¾ æ‰‹æ•°æ–™ï¼ˆ10%ï¼‰: {fee}å††")
            st.success(f"ğŸ’¹ åˆ©ç›Š: {profit}å††")

        # --- å…¥åŠ›è¨˜éŒ²ã®ä¿å­˜ï¼ˆCSVå½¢å¼ï¼‰ ---
        st.subheader("ğŸ“ è¨˜éŒ²ã‚’CSVã«ä¿å­˜")
        if st.button("è¨˜éŒ²ã‚’ä¿å­˜ã™ã‚‹"):
            now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
            record_df = pd.DataFrame([{
                "æ—¥æ™‚": now,
                "å•†å“å": predicted_name,
                "ã‚¸ãƒ£ãƒ³ãƒ«": genre,
                "ä»•å…¥ã‚Œä¾¡æ ¼": cost_price,
                "è²©å£²ä¾¡æ ¼": sell_price,
                "æ‰‹æ•°æ–™": fee,
                "åˆ©ç›Š": profit
            }])
            record_csv = record_df.to_csv(index=False).encode("utf-8")
            st.download_button("â¬‡ï¸ ã“ã®è¨˜éŒ²ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", record_csv, "record.csv", "text/csv")

        # --- ã‚µãƒãƒ¼ãƒˆãƒªãƒ³ã‚¯ ---
        st.subheader("ğŸ“š ãŠå½¹ç«‹ã¡ãƒªãƒ³ã‚¯")
        st.markdown("- ğŸŸ¥ [ãƒ¡ãƒ«ã‚«ãƒª å‡ºå“ãƒšãƒ¼ã‚¸](https://www.mercari.com/jp/sell/)")
        st.markdown("- ğŸŸ¥ [ãƒ¡ãƒ«ã‚«ãƒª é€æ–™æ—©è¦‹è¡¨ï¼ˆæœ€æ–°ï¼‰](https://help.jp.mercari.com/guide/articles/1080/)")
        st.markdown("- ğŸŸ¦ [PayPayãƒ•ãƒªãƒ å‡ºå“ãƒšãƒ¼ã‚¸](https://paypayfleamarket.yahoo.co.jp/sell)")
        st.markdown("- ğŸŸ¦ [PayPayãƒ•ãƒªãƒ ç™ºé€æ–¹æ³•ã‚¬ã‚¤ãƒ‰](https://paypayfleamarket.yahoo.co.jp/contents/shipping)")

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
